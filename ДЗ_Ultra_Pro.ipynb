{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Задание"
      ],
      "metadata": {
        "id": "ujUTHlu4BKay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Распознайте рукописную цифру, написанную на листе от руки.\n",
        "Последовательность шагов следующая:\n",
        "\n",
        "*   На бумаге рисуем произвольную цифру (желательно нарисовать цифру размером не\n",
        "более 5 * 5 мм и без наклона. В занятии нейронка обучалась на цифрах американских студентов. Эти цифры были написаны на тетрадных листах в клетку и имели схожий размер).\n",
        "*   Фотографируем. Загружаем фото в Collaboratory.\n",
        "*   С помощью функции image.load_img(path, target_size=(28, 28), color_mode = ‘grayscale’) загружаем картинку в переменную.\n",
        "*   С помощью функции image.img_to_array(img) преобразуем изображение в numpy-массив.\n",
        "*   Выполняем инверсию цветов, нормирование и решейп массива.\n",
        "*   Выполняем распознавание собственной рукописной цифры.\n",
        "\n",
        "Примечание: точность распознавания рукописных цифр может быть достаточно низкой, т.к. рукописные цифры после преобразований хоть и похожи на содержащиеся в базе, но могут отличаться по конфигурации, толщине линий и т.д."
      ],
      "metadata": {
        "id": "vKgnksZcEAdw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Импорт необходимых библиотек для работы с распознаванием цифр\n",
        "В этом блоке подключаются модули, необходимые для загрузки обучающего датасета и создания нейронной сети:\n",
        "\n",
        "- from tensorflow.keras.datasets import mnist — загрузка встроенного набора данных MNIST с изображениями рукописных цифр (28×28 пикселей).\n",
        "\n",
        "- from tensorflow.keras import utils — утилиты Keras, включая to_categorical для one-hot кодирования меток.\n",
        "\n",
        "- from tensorflow.keras.models import Sequential — используется для создания модели нейронной сети типа \"последовательная\".\n",
        "\n",
        "- from tensorflow.keras.layers import Dense — импорт слоя плотных (полносвязных) нейронов.\n",
        "\n",
        "- import numpy as np — работа с массивами и матрицами (NumPy — основной инструмент для обработки числовых данных)."
      ],
      "metadata": {
        "id": "eGs7HS38B7dP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os                                   # Работа с файловой системой\n",
        "import warnings                             # Подавление предупреждений\n",
        "import numpy as np                         # Работа с массивами\n",
        "\n",
        "from tensorflow.keras import utils         # Утилиты Keras (to_categorical и др.)\n",
        "from tensorflow.keras.datasets import mnist  # Загрузка датасета MNIST\n",
        "from tensorflow.keras.layers import Dense  # Полносвязный слой\n",
        "from tensorflow.keras.models import Sequential  # Создание нейросети\n",
        "\n",
        "# Отключаем предупреждения, чтобы не мешали выводу\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "FLWztPNsEXur"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Подготовка данных из набора MNIST\n",
        "В этом блоке производится загрузка и предварительная обработка изображений рукописных цифр из набора MNIST:\n",
        "\n",
        "Происходи загрузка данных:\n",
        "- mnist.load_data() загружает обучающую и тестовую выборки, содержащие изображения (размером 28×28 пикселей) и соответствующие им метки.\n",
        "\n",
        "Изменение формы входных данных:\n",
        "- Изображения преобразуются в векторы длиной 784 (28×28) с помощью reshape, чтобы передать их в полносвязную нейронную сеть.\n",
        "\n",
        "Нормализация:\n",
        "- Все пиксели приводятся к диапазону [0, 1], делением на 255, и тип данных меняется на float32.\n",
        "\n",
        "Преобразование меток:\n",
        "- Метки классов (y_train и y_test) переводятся в формат one-hot encoding, где каждая цифра представляется как вектор из 10 элементов (по числу классов от 0 до 9)."
      ],
      "metadata": {
        "id": "r1jOESuUCviA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train_org, y_train_org), (x_test_org, y_test_org) = mnist.load_data()\n",
        "\n",
        "x_train = x_train_org.reshape(x_train_org.shape[0], -1)\n",
        "x_test = x_test_org.reshape(x_test_org.shape[0], -1)\n",
        "\n",
        "# Преобразование x_train в тип float32 (числа с плавающей точкой) и нормализация\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "\n",
        "# Преобразование x_test в тип float32 (числа с плавающей точкой) и нормализация\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "CLASS_COUNT = 10\n",
        "\n",
        "\n",
        "# Преобразование ответов в формат one_hot_encoding\n",
        "y_train = utils.to_categorical(y_train_org, CLASS_COUNT)\n",
        "y_test = utils.to_categorical(y_test_org, CLASS_COUNT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vb_-JelpEa5k",
        "outputId": "2bddf0c5-1d75-4434-848c-64b59449a6f2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Создание и компиляция нейронной сети для распознавания цифр\n",
        "В этом блоке формируется архитектура нейронной сети и её подготовка к обучению:\n",
        "\n",
        "Выполняется моздание модели, используется последовательная модель Sequential, где слои добавляются один за другим.\n",
        "\n",
        "Полносвязные слои:\n",
        "\n",
        "- Первый скрытый слой содержит 800 нейронов с активацией ReLU и принимает на вход векторы длиной 784 (28×28 пикселей, развернутые в вектор).\n",
        "\n",
        "- Второй скрытый слой — 400 нейронов с активацией ReLU, что помогает модели учиться сложным представлениям.\n",
        "\n",
        "Выходной слой:\n",
        "- Состоит из 10 нейронов (по числу классов от 0 до 9), использует функцию активации softmax для получения вероятностей классов.\n",
        "\n",
        "Далее выполняется компиляция:\n",
        "- Используется функция потерь categorical_crossentropy (подходит для многоклассовой классификации), оптимизатор Adam и метрика точности (accuracy)."
      ],
      "metadata": {
        "id": "to-XIIZ2DNMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание последовательной модели\n",
        "model = Sequential()\n",
        "\n",
        "# Добавление полносвязного слоя на 800 нейронов с relu-активацией\n",
        "model.add(Dense(800, input_dim=784, activation=\"relu\"))\n",
        "\n",
        "# Добавление полносвязного слоя на 400 нейронов с relu-активацией\n",
        "model.add(Dense(400, activation=\"relu\"))\n",
        "\n",
        "# Добавление полносвязного слоя с количеством нейронов по числу классов с softmax-активацией\n",
        "model.add(Dense(CLASS_COUNT, activation=\"softmax\"))\n",
        "\n",
        "# Компиляция модели\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "5iorRVdEEa6P"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучение нейронной сети\n",
        "В данном блоке происходит процесс обучения модели на подготовленных данных:\n",
        "\n",
        "Входные данные:\n",
        "- Используются нормализованные векторы изображений x_train и соответствующие one-hot метки y_train.\n",
        "\n",
        "Параметры обучения:\n",
        "\n",
        "- batch_size=128 — сеть обновляет веса после обработки каждого батча из 128 примеров.\n",
        "\n",
        "- epochs=15 — модель проходит 15 полных циклов по всему набору данных.\n",
        "\n",
        "- verbose=1 — вывод подробной информации о ходе обучения в консоль.\n"
      ],
      "metadata": {
        "id": "t2gjT10mDpDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    x_train,  # обучающая выборка, входные данные\n",
        "    y_train,  # обучающая выборка, выходные данные\n",
        "    batch_size=128,  # кол-во примеров, которое обрабатывает нейронка перед одним изменением весов\n",
        "    epochs=15,  # количество эпох, когда нейронка обучается на всех примерах выборки\n",
        "    verbose=1,\n",
        ")  # 0 - не визуализировать ход обучения, 1 - визуализировать"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvWyVBF9El_j",
        "outputId": "b855cd20-a665-454e-feb1-f67535a8dbf8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8884 - loss: 0.3777\n",
            "Epoch 2/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9759 - loss: 0.0762\n",
            "Epoch 3/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9841 - loss: 0.0489\n",
            "Epoch 4/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9901 - loss: 0.0306\n",
            "Epoch 5/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9931 - loss: 0.0214\n",
            "Epoch 6/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9939 - loss: 0.0197\n",
            "Epoch 7/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9943 - loss: 0.0172\n",
            "Epoch 8/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9966 - loss: 0.0107\n",
            "Epoch 9/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.0148\n",
            "Epoch 10/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9968 - loss: 0.0097\n",
            "Epoch 11/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.0163\n",
            "Epoch 12/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0101\n",
            "Epoch 13/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0065\n",
            "Epoch 14/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0065\n",
            "Epoch 15/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9955 - loss: 0.0138\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x788361deabd0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Далее были реализованы операции по сохранению и восстановлению обученных параметров нейронной сети:\n",
        "\n",
        "Сохранение весов:\n",
        "- model.save_weights(\"dz_ultra_pro.weights.h5\") — сохраняет текущие веса модели в файл с расширением .h5. Это удобно для последующего использования без необходимости повторного обучения.\n",
        "\n",
        "Загрузка весов:\n",
        "- model.load_weights(\"dz_ultra_pro.weights.h5\") — загружает сохранённые веса из файла, позволяя восстановить состояние модели и сразу использовать её для предсказаний или дальнейшего обучения."
      ],
      "metadata": {
        "id": "c7s8BvafD4UO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights(\"dz_ultra_pro.weights.h5\")\n",
        "model.load_weights(\"dz_ultra_pro.weights.h5\")"
      ],
      "metadata": {
        "id": "Odx1EHJ-E3NJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Далее подключаются необходимые инструменты для работы с изображениями и подключения к Google Диску:\n",
        "\n",
        "- from tensorflow.keras.preprocessing import image — загрузка и предобработка изображений.\n",
        "\n",
        "- import matplotlib.pyplot as plt — библиотека для визуализации изображений и графиков.\n",
        "\n",
        "- from google.colab import drive и drive.mount('/content/drive') — монтирование Google Диска для загрузки и сохранения файлов в среде Google Colaboratory."
      ],
      "metadata": {
        "id": "ts8GAM3JEHXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "zTGuxsIzE6K7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4db9c43f-2bfa-40ef-ad1a-57b10fbed9fe",
        "collapsed": true
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BCTXWkBHa-Yc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка, предобработка и визуализация пользовательского изображения\n",
        "В этом блоке происходит подготовка рукописной цифры, загруженной с Google Диска, для распознавания:\n",
        "\n",
        "- image.load_img() загружает фото по пути img_path, масштабируя его до размера 28×28 пикселей и переводя в оттенки серого.\n",
        "\n",
        "- Преобразование в массив: image.img_to_array() конвертирует изображение в числовой массив.\n",
        "\n",
        "- Инверсия цветов: для правильного распознавания цвета цифры и фона цвета инвертируются: белый становится чёрным и наоборот (255 - img_array).\n",
        "\n",
        "- Пороговая фильтрация: пиксели с интенсивностью ниже 150 устанавливаются в 0 — это помогает убрать шумы и выделить фигуру.\n",
        "\n",
        "- Визуализация: отображение обработанного изображения с помощью plt.imshow() в оттенках серого.\n",
        "\n",
        "- Подготовка к модели: массив преобразуется в вектор, нормируется (деление на 255) и приводится к типу float32 для подачи в нейронную сеть."
      ],
      "metadata": {
        "id": "hpnG721VEXrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = \"/content/drive/My Drive/Photo/4.jpg\"\n",
        "img = image.load_img(img_path, target_size=(28, 28), color_mode='grayscale')\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = 255 - img_array\n",
        "img_array = np.where(img_array < 150, 0, img_array)\n",
        "plt.imshow(img_array, cmap=\"gray\")\n",
        "img_train = img_array.reshape(1, -1).astype(\"float32\")  / 255.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "bJse3V6bE6Lh",
        "outputId": "d291e13d-e19c-416f-aad2-660c49e6d87e",
        "collapsed": true
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Предсказание класса рукописной цифры.\n",
        "\n",
        "Прогнозирование: model.predict(img_train) вычисляет вероятности для каждого из 10 классов (цифр от 0 до 9).\n",
        "\n",
        "Определение класса: np.argmax(prediction) выбирает класс с максимальной вероятностью — это и есть распознанная цифра."
      ],
      "metadata": {
        "id": "WxGIODISEyM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict(img_train)\n",
        "predicted_class = np.argmax(prediction)\n",
        "print(\"Распознанная цифра:\", predicted_class)"
      ],
      "metadata": {
        "id": "_sTXbjdEFDWJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19d4bb39-f458-4ea6-8a3e-65b6812a3594"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step\n",
            "Распознанная цифра: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Вывод по заданию\n",
        "В данном задании была создана и обучена глубокая нейронная сеть для распознавания рукописных цифр из набора MNIST. Модель успешно справилась с задачей классификации, достигнув высокой точности благодаря использованию нескольких полносвязных слоев с функцией активации ReLU и softmax на выходе. Кроме того, была реализована обработка пользовательского изображения: оно было загружено, приведено к нужному формату, инвертировано и нормализовано для корректного распознавания. Итоговое предсказание продемонстрировало, что сеть способна распознавать собственноручно написанные цифры, хотя качество распознавания может зависеть от особенностей изображения — размера, толщины линий и контраста."
      ],
      "metadata": {
        "id": "3f4KoFTYE2DB"
      }
    }
  ]
}